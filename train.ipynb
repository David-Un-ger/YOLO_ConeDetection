{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "train_1.2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FinnHendricks/YOLO_ConeDetection/blob/main/train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "corquhFculZ5"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/FinnHendricks/YOLO_ConeDetection/blob/main/train.ipynb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81gPOu_AJ_RL"
      },
      "source": [
        "\n",
        "## Steps:\n",
        "- basic CNN architecture / class - ok\n",
        "- input pipeline - ok\n",
        "- visualisation - ok\n",
        "- IoU - ok\n",
        "- Loss function\n",
        "- non maxima suppression\n",
        "- Train/optimizer\n",
        "- training\n",
        "- better architecture, batch_norm\n",
        "- augmentation\n",
        "\n",
        "- result: sigmoid on center + exponent of w+h\n",
        "\n",
        "## General steps:\n",
        "- Yolo on cones \n",
        "- introduce different scales\n",
        "- Yolo on COCO\n",
        "- introduce anchor boxes\n",
        "- CARLA data\n",
        "- Yolo on Carla\n",
        "\n",
        "## yolo-format (called label(s) in this notebook:\n",
        "- each image has its own label file with the same file name\n",
        "- each cone of an image is described by one line\n",
        "- Format in txt files: class, x_center, y_center, width_bbox, height_bbox\n",
        "- Format used in this notebook: [objectness, x_center, y_center, width_bbox, height_bbox, class0, c1, c2, c3, c4, c5, c6]\n",
        "\n",
        "- 0 blue\n",
        "- 1 yellow\n",
        "- 2 orange-small\n",
        "- 3 orange-big (shown in red)\n",
        "- 4 yellow-big (shown in white)\n",
        "- 5 green\n",
        "- 6 lying\n",
        "\n",
        "## YOLO-Output (called y / y_pred / y_true in this notebook:\n",
        "\n",
        "Per S x S grid cell, e.g. 8x8:\n",
        "x,y, height, width, objectness, prob per class\n",
        "\n",
        "--> 8x8x(4+1+7) = 8x8x12 = 768 output neurons\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ULDlKy0J_RP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "addafd78-56fc-4675-d576-32c8a5fba450"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.config.list_physical_devices())\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXNLkRGQ0tfx",
        "outputId": "bd1a4e9e-7e84-42ed-cd61-594415743c3b"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Sep 26 23:37:13 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   40C    P0    26W / 250W |      2MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aps7m3-ePmmZ"
      },
      "source": [
        "partial_dataset = False\n",
        "\n",
        "if partial_dataset:\n",
        "    !gdown https://drive.google.com/uc?id=1OBJucC4oklE9-k4mZ5nQheoor6R548Tu  \n",
        "else:\n",
        "    !gdown https://drive.google.com/uc?id=1o7MC17JeqYWdeG9jUkXbXeVpPSSCtHV6"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny--SUcWe1zU"
      },
      "source": [
        "%%capture\n",
        "if partial_dataset:\n",
        "    !unzip -u \"/content/cones_multi_class_partial.zip\" -d \"/content/\";\n",
        "    directory_train = '/content/cones_multi_class_partial/train'\n",
        "    directory_test = '/content/cones_multi_class_partial/test/'\n",
        "    train_size = 128\n",
        "else:\n",
        "    !unzip -u \"/content/cones_multi_class.zip\" -d \"/content/\";\n",
        "    directory_train = '/content/cones_multi_class/train'\n",
        "    directory_test = '/content/cones_multi_class/test/'\n",
        "    train_size = 21_067 - 14  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfj_i_V_FtJJ",
        "outputId": "a04158f2-58fd-4330-d926-7275b54b8e37"
      },
      "source": [
        "\n",
        "# download helper file\n",
        "!gdown https://drive.google.com/uc?id=1OM2CgpOrturcsnqiOmMydwXAghpeveC-\n",
        "\n",
        "from helper_yolo import iou_width_height as iou\n",
        "from helper_yolo import non_max_suppression as nms\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1OM2CgpOrturcsnqiOmMydwXAghpeveC-\n",
            "To: /content/helper_yolo.py\n",
            "\r  0% 0.00/18.9k [00:00<?, ?B/s]\r100% 18.9k/18.9k [00:00<00:00, 16.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OF510ijJ_RQ"
      },
      "source": [
        "\n",
        "img_width = 512#800\n",
        "img_height = 512#320\n",
        "img_channels = 3\n",
        "grid_X = 8\n",
        "grid_Y = 8\n",
        "batch_size = 16\n",
        "epochs = 5\n",
        "num_classes = 7  # blue, yellow, orange_small, o_big, yellow, green, lying\n",
        "initial_learning_rate = 0.01\n",
        "#final_learning_rate = 0.001\n",
        "#learning_rate_decay_factor = (final_learning_rate / initial_learning_rate) ** (1/epochs)\n",
        "steps_per_epoch = int(train_size/batch_size)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyacmawRa0fH"
      },
      "source": [
        "# convert the label given in the csv files to a matrix that can be used as y\n",
        "\n",
        "def convert_label_to_y(label, file):\n",
        "    object_class, x_center, y_center, width_bbox, height_bbox = list(map(float, label))\n",
        "\n",
        "    # find relevant grid cell for predicting the object\n",
        "    i, j = int(y_center * grid_Y), int(x_center * grid_X) # i row, j column \n",
        "\n",
        "    assert i < grid_Y, \"center must be within the image\" + str(file.name)\n",
        "    assert j < grid_X, \"center must be within the image\" + str(file.name)\n",
        "\n",
        "    x_center_bbox = x_center * grid_X - j  # find center relative to cell; 0...1\n",
        "    y_center_bbox = y_center * grid_Y - i\n",
        "\n",
        "    width_bbox *= grid_X  # scale box size, that 1 equals the grid size -> range of object size makes more sense\n",
        "    height_bbox *= grid_Y\n",
        "\n",
        "    c0, c1, c2, c3, c4, c5, c6 = tf.one_hot(tf.range(7), 7)[int(object_class)] # class of the cone\n",
        "    # objectness, x_center, y_center, width_bbox, height_bbox, class0, c1, c2, c3, c4, c5, c6\n",
        "    y = np.zeros((grid_X, grid_Y, num_classes+5 ))\n",
        "    y[j, i] = [1.0, x_center_bbox, y_center_bbox, width_bbox, height_bbox, c0, c1, c2, c3, c4, c5, c6]\n",
        "    return y"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mvUMv0eJ_RR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7196e6de-e5b6-4f1d-f87b-1206a1513a87"
      },
      "source": [
        "black_list_files_train = [\"00001505_skid-pad.txt\", \n",
        "                    \"Renningen_08_04_video_second_frame_8.txt\", \n",
        "                    \"Aidlingen_07_12_video_first_frame_4.txt\",\n",
        "                    \"Aidlingen_07_12_video_first_frame_8.txt\",\n",
        "                    \"upbracing-classes.txt\",\n",
        "                    \"00001833_skid-pad.txt\",\n",
        "                    \"00047.txt\",\n",
        "                    \"Aidlingen_07_12_video_first_frame_7.txt\",\n",
        "                    \"00001465_skid-pad.txt\",\n",
        "                    \"Aidlingen_07_12_video_first_frame_5.txt\",\n",
        "                    \"Aidlingen_07_12_video_first_frame_6.txt\",\n",
        "                    \"213(2).txt\",\n",
        "                    \"Aidlingen_07_12_video_first_frame_3.txt\",\n",
        "                    \"00001464_skid-pad.txt\"\n",
        "                    ]  \n",
        "                    # the labels of this samples are currupt and may not be used\n",
        "\n",
        "black_list_files_test = []\n",
        "\n",
        "def read_data(path, black_list_files):\n",
        "    jpg_paths = []\n",
        "    n_samples = 0\n",
        "    for file in os.listdir(path):\n",
        "        if file.endswith(\".txt\"):\n",
        "            n_samples += 1\n",
        "    n_samples -= len(black_list_files)\n",
        "\n",
        "    sample_ctr = 0\n",
        "    y = np.zeros((n_samples, grid_X, grid_Y, num_classes+5 ))\n",
        "    for file in os.listdir(path):\n",
        "        if file.endswith(\".txt\"):\n",
        "          \n",
        "            if file in black_list_files:\n",
        "                continue\n",
        "            try:\n",
        "              with open(os.path.join(path, file), \"r\") as file:\n",
        "                for label in file:\n",
        "                    label = label.strip().split(\" \")\n",
        "                    y[sample_ctr] += convert_label_to_y(label, file) \n",
        "            except:\n",
        "              print(str(file))\n",
        "              continue\n",
        "            #find the corresponding image path\n",
        "            jpg_path = file.name.strip(\"txt\")+\"jpg\"\n",
        "            jpg_paths.append(jpg_path)\n",
        "            sample_ctr += 1\n",
        "            \n",
        "    return jpg_paths, y\n",
        "            \n",
        "jpg_paths_train, y_train = read_data(directory_train, black_list_files_train)\n",
        "jpg_paths_test, y_test = read_data(directory_test, black_list_files_test)\n",
        "print(y_train.shape[0], \" train images found.\")\n",
        "print(y_test.shape[0], \" test images found.\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "21053\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IB0rwgMJ_RS"
      },
      "source": [
        "# input data\n",
        "\n",
        "ds_train = tf.data.Dataset.from_tensor_slices((jpg_paths_train, y_train))\n",
        "ds_test = tf.data.Dataset.from_tensor_slices((jpg_paths_test, y_test))\n",
        "\n",
        "def read_image(image_file, y):\n",
        "    image = tf.io.read_file(image_file)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)#, dtype=tf.float32)\n",
        "    return image, y\n",
        "\n",
        "def resize(image, y):\n",
        "    image = tf.image.resize(image, [img_height, img_width], method=tf.image.ResizeMethod.BILINEAR,preserve_aspect_ratio=False)\n",
        "    image = image / 255. # rescale\n",
        "    return image, y\n",
        "\n",
        "\n",
        "#ds_train = ds_train.map(read_image).map(resize_and_crop).map(augment).batch(batch_size)\n",
        "ds_train = ds_train.map(read_image).map(resize).shuffle(train_size).batch(batch_size).prefetch(2)\n",
        "ds_test = ds_test.map(read_image).map(resize).batch(batch_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsDSWIRrJ_RS"
      },
      "source": [
        "def visualize(image):\n",
        "    fig = plt.figure(figsize=(10,10))\n",
        "    plt.title('Image')\n",
        "    plt.imshow(image)\n",
        "\n",
        "\n",
        "def draw_bounding_box(image, y, draw_grid=True):\n",
        "    image = image.numpy()\n",
        "    h, w, _ = image.shape   \n",
        "    relevant_grids = np.argwhere(y[:,:,0] >= 0.3)  # get relevant grids that contain objects with objectness > 0.3 \n",
        "    print(relevant_grids)\n",
        "    print(type(y))\n",
        "    for grid in relevant_grids:\n",
        "        print(\"grid\", grid)\n",
        "        print(\"Y\", y.shape)\n",
        "        print(y[list(grid)].shape)\n",
        "        objectness, x_center_bbox, y_center_bbox, width_bbox, height_bbox = y[list(grid)][:5]\n",
        "        \n",
        "        #blue, yellow, orange, orange-big, yellow-big, green, lying\n",
        "        object_class = y[list(grid)][5:]\n",
        "        object_class = np.argmax(object_class)\n",
        "\n",
        "        #Todo: class when not 0 / 1\n",
        "        colors = {\n",
        "            0: [0, 0, 255],\n",
        "            1: [255, 255, 0],\n",
        "            2: [255, 165, 0],\n",
        "            3: [255, 0  , 0],\n",
        "            4: [255, 255, 255],\n",
        "            5: [0  , 255, 0],\n",
        "            6: [0  , 0  , 0]\n",
        "        }\n",
        "        color = colors[object_class]\n",
        "        color = color * objectness  # adjust brightness based on objectness\n",
        "\n",
        "        color = tf.make_tensor_proto(color)\n",
        "        color = tf.make_ndarray(color).astype(int).tolist()\n",
        "    \n",
        "        x_center = (x_center_bbox + grid[0])/grid_X*w\n",
        "        y_center = (y_center_bbox + grid[1])/grid_Y*h\n",
        "        box_width = width_bbox / grid_X * w\n",
        "        box_height = height_bbox / grid_Y * h\n",
        "        \n",
        "        x_min = int(x_center - box_width/2)\n",
        "        x_max = int(x_center + box_width/2)\n",
        "        y_min = int(y_center - box_height/2)\n",
        "        y_max = int(y_center + box_height/2)\n",
        "        \n",
        "        image = cv2.rectangle(image, (x_min, y_min), (x_max, y_max), color, 2) \n",
        "        if draw_grid:\n",
        "            grid_points = [[(int(i/grid_X*w), 0),(int(i/grid_X*w), h)]for i in range(grid_X)] + \\\n",
        "                          [[(0, int(i/grid_Y*h)),(w, int(i/grid_Y*h))]for i in range(grid_Y)]\n",
        "            for points in grid_points: \n",
        "                cv2.line(image, points[0], points[1], [255, 255, 255], 1) \n",
        "\n",
        "    return image\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "ngnBcetkJ_RT"
      },
      "source": [
        "for images, y in ds_test:\n",
        "    #print(images.shape)\n",
        "    i = np.random.randint(0, batch_size)\n",
        "    image = draw_bounding_box(images[i], y[i], draw_grid=True)\n",
        "    visualize(image)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgT8Ije8J_RU"
      },
      "source": [
        "\"\"\"def label2box(cone):\n",
        "    x_center = float(cone[1])*img_width\n",
        "    y_center = float(cone[2])*img_height\n",
        "    box_width = float(cone[3])*img_width\n",
        "    box_height = float(cone[4])*img_height\n",
        "\n",
        "    x_min = int(x_center - box_width/2)\n",
        "    x_max = int(x_center + box_width/2)\n",
        "    y_min = int(y_center - box_height/2)\n",
        "    y_max = int(y_center + box_height/2)\n",
        "    return (x_min, x_max, y_min, y_max)\n",
        "\n",
        "\"\"\"\n",
        "# http://datahacker.rs/tensorflow2-0-yolov3/\n",
        "def interval_overlap(interval_1, interval_2):\n",
        "    x1, x2 = interval_1\n",
        "    x3, x4 = interval_2\n",
        "    if x3 < x1: # if interval_2 is left of interval_1\n",
        "        return 0 if x4 < x1 else (min(x2,x4) - x1)\n",
        "    else:\n",
        "        return 0 if x2 < x3 else (min(x2,x4) - x3)\n",
        "\n",
        "def IoU(box1, box2):\n",
        "    xmin1, xmax1, ymin1, ymax1 = box1\n",
        "    xmin2, xmax2, ymin2, ymax2 = box2\n",
        "    intersect_w = interval_overlap([xmin1, xmax1], [xmin2, xmax2])\n",
        "    intersect_h = interval_overlap([ymin1, ymax1], [ymin2, ymax2])\n",
        "    intersect_area = intersect_w * intersect_h\n",
        "\n",
        "    w1, h1 = xmax1 - xmin1, ymax1 - ymin1\n",
        "    w2, h2 = xmax2 - xmin2, ymax2 - ymin2\n",
        "\n",
        "    union_area = w1*h1 + w2*h2 - intersect_area\n",
        "\n",
        "    if union_area == 0:\n",
        "        iou = 0\n",
        "    else:\n",
        "        iou = float(intersect_area) / union_area\n",
        "    return iou\n",
        "print(IoU((10,20,10,20), (10,20,10,30)))\n",
        "print(IoU((10,25,7,20), (10,20,10,30)))\n",
        "print(IoU((100,250,7,20), (10,20,10,30)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjwKa0m3J_RU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qz73P3BlJ_RV"
      },
      "source": [
        "input_layer = keras.layers.Input(shape=(img_width, img_height, img_channels))\n",
        "x = keras.layers.Conv2D(16, (3, 3), strides=(2,2), activation='relu', padding='same')(input_layer)\n",
        "x = keras.layers.Conv2D(32, (3, 3), strides=(2,2), activation='relu', padding='same')(x)\n",
        "x = keras.layers.Conv2D(64, (3, 3), strides=(2,2), activation='relu', padding='same')(x)\n",
        "x = keras.layers.Conv2D(64, (3, 3), strides=(1,1), activation='relu', padding='same')(x)\n",
        "x = keras.layers.Conv2D(128, (3, 3), strides=(2,2), activation='relu', padding='same')(x)\n",
        "x = keras.layers.Conv2D(128, (3, 3), strides=(2,2), activation='relu', padding='same')(x)\n",
        "x = keras.layers.Conv2D(128, (3, 3), strides=(2,2), activation='relu', padding='same')(x)\n",
        "x = keras.layers.Conv2D(64, (1, 1), strides=(1,1), activation='relu', padding='same')(x)\n",
        "# using just a single anchor\n",
        "out_channels = 5 + 7  # [objectness, x_center, y_center, width_bbox, height_bbox, class0, c1, c2, c3, c4, c5, c6]\n",
        "x = keras.layers.Conv2D(out_channels, (1, 1), strides=(1,1), activation='linear', padding='same')(x)\n",
        "\n",
        "# Instantiate the model\n",
        "yolo = keras.Model(inputs=input_layer, outputs=x)\n",
        "print(yolo.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUbc2XFHJ_RV"
      },
      "source": [
        "\n",
        "def loss_function(y, y_pred):\n",
        "    \"\"\"\n",
        "    label:\n",
        "    the true labels contain several cones with each: class, x_center, y_center, width_bbox, height_bbox\n",
        "\n",
        "    y_pred:\n",
        "    from the CNN we get a tensor 8x8x12 (8x8 grid and 12 values per grid cell)\n",
        "    per grid we define:\n",
        "    [objectness, x_center, y_center, width_bbox, height_bbox, class0, c1, c2, c3, c4, c5, c6]\n",
        "    \"\"\"\n",
        "\n",
        "    # loss for predicting objects where no objects are\n",
        "    bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    # I skip this for now and just penalize all predictions (weight norm penalty using L1 Loss -> enforce sparsity)\n",
        "\n",
        "\n",
        "    # loss for not predicting the objectness \n",
        "    obj_loss = bce(y[...,0], y_pred[...,0])  # y[...,0] adresses all objectness scores\n",
        "\n",
        "    # loss for the box\n",
        "    box_loss = tf.keras.losses.mean_squared_error(y[...,1:5], y_pred[...,1:5])\n",
        "\n",
        "    # loss for the class\n",
        "    class_loss = 0 # ToDo!\n",
        "\n",
        "    # regularization\n",
        "    regularization_lasso = tf.keras.losses.mean_absolute_error(y_pred, tf.zeros_like(y_pred))\n",
        "\n",
        "    loss = obj_loss + box_loss + class_loss + 0.1*regularization_lasso\n",
        "    return loss\n",
        "yolo.compile(optimizer='adam', loss=loss_function)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qG2xt4uOtu8"
      },
      "source": [
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=10,\n",
        "    verbose=2,\n",
        "    # Only run validation using the first 10 batches of the dataset\n",
        "    # using the `validation_steps` argument\n",
        "    validation_data=ds_test,\n",
        "    validation_steps=10,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrsJpI-9oCrI"
      },
      "source": [
        "\n",
        "for images, y in ds_test:\n",
        "    #print(images.shape)\n",
        "    i = np.random.randint(0, batch_size)\n",
        "    y_pred = yolo.predict(images)\n",
        "    print(y_pred[i].shape)\n",
        "    print(y_pred.shape)\n",
        "    print(i)\n",
        "    image = draw_bounding_box(images[i], tf.convert_to_tensor(y_pred[i]), draw_grid=True)\n",
        "    visualize(image)\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmRZx4b4owjV"
      },
      "source": [
        "y_pred[i].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "yEo2N037J_RW"
      },
      "source": [
        "# loss, metrics = yolo.evaluate(ds_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsRhUtO4J_RW"
      },
      "source": [
        "\"\"\"\n",
        "import matplotlib.pyplot as plt \n",
        "\n",
        "def plot_learningCurve(history):\n",
        "  # Plot training & validation accuracy values\n",
        "    epoch_range = range(0, epochs)\n",
        "    plt.plot(epoch_range, history.history['accuracy'])\n",
        "    plt.plot(epoch_range, history.history['val_accuracy'])\n",
        "    plt.title('Model accuracy')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "    # Plot training & validation loss values\n",
        "    plt.plot(epoch_range, history.history['loss'])\n",
        "    plt.plot(epoch_range, history.history['val_loss'])\n",
        "    plt.title('Model loss')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Val'], loc='upper left')\n",
        "    plt.show()\n",
        "\n",
        "plot_learningCurve(history)\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}